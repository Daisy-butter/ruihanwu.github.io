<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.27.3 by Michael Rose
  Copyright 2013-2025 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Dual System VLA Approach - Ruihan’s Log</title>
<meta name="description" content="Notes on Embodied Intelligence, World Models, and Robotics.">


  <meta name="author" content="Ruihan Wu">
  
  <meta property="article:author" content="Ruihan Wu">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Ruihan’s Log">
<meta property="og:title" content="Dual System VLA Approach">
<meta property="og:url" content="https://daisy-butter.github.io/ruihanwu.github.io/dual-system-VLA/">


  <meta property="og:description" content="Notes on Embodied Intelligence, World Models, and Robotics.">







  <meta property="article:published_time" content="2025-10-26T00:00:00+00:00">






<link rel="canonical" href="https://daisy-butter.github.io/ruihanwu.github.io/dual-system-VLA/">












<!-- end _includes/seo.html -->



  <link href="/ruihanwu.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Ruihan’s Log Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/ruihanwu.github.io/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--post" dir="ltr">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/ruihanwu.github.io/">
          Ruihan’s Log
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="https://mmistakes.github.io/minimal-mistakes/docs/quick-start-guide/"
                
                
              >Quick-Start Guide</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      <article class="post-content" style="max-width:800px;margin:60px auto;padding:0 1rem;">
  <header style="margin-bottom:1.5rem;">
    <h1 style="font-size:2rem;margin-bottom:.3rem;">Dual System VLA Approach</h1>
    <p style="color:#777;font-size:.9rem;">October 26, 2025</p>
  </header>

  <div class="content" style="line-height:1.7;font-size:1.05rem;color:#333;">
    <style>
        .content img { display: block; margin: 1.5rem auto; max-width: 100%; border-radius: 6px; }
    </style>
    <style>
  /* ----------- 页面总体样式 ----------- */
  .post-wrapper {
    display: flex;
    flex-direction: row;
    justify-content: center;
    gap: 40px;
    max-width: 1200px;
    margin: 0 auto;
    padding: 2rem 1rem;
  }

  .post-main {
    flex: 3;
    max-width: 800px;
  }

  .post-toc {
    flex: 1;
    position: sticky;
    top: 120px;
    align-self: flex-start;
    background: var(--card);
    border-radius: 10px;
    padding: 1rem 1.2rem;
    box-shadow: 0 2px 10px rgba(0,0,0,0.05);
    height: fit-content;
  }

  .post-toc h3 {
    font-size: 1rem;
    margin-bottom: 0.8rem;
    border-bottom: 1px solid #ddd;
    padding-bottom: 0.3rem;
  }

  .post-toc ul {
    list-style: none;
    padding-left: 0;
    margin: 0;
  }

  .post-toc li {
    margin-bottom: 0.4rem;
  }

  .post-toc a {
    color: var(--subtext);
    text-decoration: none;
    font-size: 0.9rem;
  }

  .post-toc a:hover {
    color: #007acc;
  }

  /* ----------- 标题区与摘要 ----------- */
  .post-header {
    text-align: center;
    margin-bottom: 1.5rem;
  }

  .post-header h1 {
    font-size: 1.75rem;
    font-weight: 700;
    margin-bottom: 0.5rem;
  }

  .post-header .meta {
    color: #777;
    font-size: 0.85rem;
  }

  .abstract-box {
    background: var(--card);
    border-left: 4px solid #007acc;
    border-radius: 6px;
    padding: 1.2rem 1.5rem;
    margin: 1.5rem 0 2rem 0;
    font-size: 0.95rem;
    color: var(--subtext);
    box-shadow: 0 2px 6px rgba(0,0,0,.05);
  }

  /* ----------- 正文部分 ----------- */
  .post-content {
    font-size: 0.97rem;
    line-height: 1.7;
    color: var(--text);
  }

  .post-content h2 {
    margin-top: 2rem;
    margin-bottom: 1rem;
    font-size: 1.2rem;
    border-left: 3px solid #007acc;
    padding-left: 10px;
  }

  .post-content img {
    display: block;
    margin: 1.2rem auto;
    max-width: 100%;
    border-radius: 6px;
    box-shadow: 0 1px 8px rgba(0,0,0,.08);
  }

  .post-content blockquote {
    border-left: 3px solid #007acc;
    padding-left: 1rem;
    color: #555;
    font-style: italic;
    margin: 1.2rem 0;
  }

  .post-content code {
    background: #f3f3f3;
    padding: 2px 5px;
    border-radius: 4px;
    font-family: monospace;
    font-size: 0.9rem;
  }

  /* ----------- 表格 ----------- */
  .post-content table {
    border-collapse: collapse;
    width: 100%;
    margin: 1.5rem 0;
    font-size: 0.9rem;
  }

  .post-content th, .post-content td {
    border: 1px solid #ddd;
    padding: 8px 10px;
  }

  .post-content th {
    background-color: #f0f0f0;
    font-weight: 600;
  }

  .post-content tr:nth-child(even) {
    background-color: #fafafa;
  }

  .post-content tr:hover {
    background-color: #f5f5f5;
  }

  /* ----------- 页脚 ----------- */
  .post-footer {
    margin-top: 3rem;
    text-align: center;
    font-size: 0.85rem;
    color: #999;
  }

  /* 夜间模式兼容 */
  body.dark-mode .post-toc { background: #2a2a2a; }
  body.dark-mode .post-toc a { color: #ccc; }
  body.dark-mode .abstract-box { background: #2b2b2b; color: #ccc; }
  body.dark-mode .post-content th { background: #333; color: #ddd; }
</style>

<!-- 在这里插入markdownify开关 -->

<!-- 这里开始markdown正文。 -->

<p>Large-scale Vision-Language-Action (VLA) research has recently shifted toward <em>dual-system architectures</em>, where high-level cognition and low-level control co-exist but operate differently. A common analogy draws on the human <strong>System-2 (cortex)</strong> — capable of abstract reasoning, task understanding, and planning — and <strong>System-1 (cerebellum/spinal circuit)</strong> — responsible for fast, reactive motor control. However, the implementation varies dramatically across recent embodied AI systems.</p>

<p>This blog post provides a high-level overview of these systems, focusing specifically on <strong>how System-2 and System-1 are constructed</strong>, <strong>what forms the intermediate representation (IR)</strong> between them, and <strong>how gradients or knowledge flow across the divide</strong>.</p>

<hr />

<h2 id="1️⃣-dual-system-with-implicit-latent-ir">1️⃣ Dual-System with <strong>implicit latent IR</strong></h2>
<p>Some VLA architectures avoid exposing the intermediate representation explicitly, instead encoding planning information and task semantics in latent vectors that are consumed directly by the controller.</p>

<h3 id="minedreamer">MineDreamer</h3>
<p>MineDreamer embodies an implicit factorization: a world-model-based System-2 predicts future states and evaluates action consequences, while a System-1 executor tracks and minimizes the latent distance toward the desired goal embedding. The <strong>Goal Q-former</strong> distills language-conditioned semantic targets into a latent embedding space, enabling visually grounded imagination without textual dispatch during execution.</p>

<p><img src="/assets/img/dual-system-vla/MineDreamer.png" alt="MineDreamer" width="600" /></p>

<h3 id="metaqueries">MetaQueries</h3>
<p>MetaQueries infers a latent <strong>skill semantic embedding</strong> from observed behavior, enabling a robot to “understand” <em>what</em> skill is being performed and reproduce it in new contexts. The planner and the controller communicate purely through the latent skill representation, capturing generalizable structure beyond explicit affordance labels or trajectories.</p>

<p><img src="/assets/img/dual-system-vla/MetaQueries.png" alt="MetaQueries" width="600" /></p>

<h3 id="knowledge-insulating-vla-models-pi05-ki-family">Knowledge-Insulating VLA Models (pi0.5-KI family)</h3>
<p>A crucial innovation in this line of work is <strong>allowing gradients from execution to flow back</strong> to the cognitive module, while protecting linguistic knowledge from being corrupted by noisy action supervision. Semantic adapters restrict the updates to <em>execution-relevant</em> representation dimensions — achieving beneficial bidirectional learning while preserving language/world understanding.</p>

<p><img src="/assets/img/dual-system-vla/KI-VLA.png" alt="KI-VLA" /></p>

<hr />

<h2 id="2️⃣-dual-system-with-explicit-intermediate-structure">2️⃣ Dual-System with <strong>explicit intermediate structure</strong></h2>
<p>Other systems emphasize clearly articulated IR that reflects task structure, spatial geometry, or sub-goal semantics, typically yielding stronger interpretability and controllability.</p>

<h3 id="internvla-n1--internvla-m1">InternVLA-N1 / InternVLA-M1</h3>
<p>These systems divide the brain into <strong>a VLM planner (System-2)</strong> and <strong>a diffusion-based motion policy (System-1)</strong>. Navigation (N1) employs pixel or latent goal tokens, while manipulation (M1) leverages explicit spatial grounding and operational hints. Crucially, execution is often asynchronous, enabling high-frequency control without blocking planning.</p>

<p><img src="/assets/img/dual-system-vla/InternVLA-N1.png" alt="InternVLA-N1" /></p>

<p><img src="/assets/img/dual-system-vla/InternVLA-M1.png" alt="InternVLA-M1" /></p>

<h3 id="saycan">SayCan</h3>
<p>SayCan pioneered the modern “LLM planner → skill executor” split. A language model selects skills conditioned on <em>affordance Q-values</em>, ensuring that what the LLM suggests is physically executable. This explicit IR-based decision filter became a canonical blueprint for dual-system alignments.</p>

<p><img src="/assets/img/dual-system-vla/SayCan.png" alt="SayCan" /></p>

<h3 id="robodual">RoboDual</h3>
<p>RoboDual takes modularity further: a <strong>Generalist System-2</strong> performs task reasoning and selects both skills and control modes, while <strong>Specialist System-1</strong> controllers are optimized for specific motion regimes. End-to-end gradient flow enables System-2 to gradually understand embodiment constraints without sacrificing structure.</p>

<p><img src="/assets/img/dual-system-vla/RoboDual.png" alt="RoboDual" /></p>

<h3 id="robobrain">RoboBrain</h3>
<p>RoboBrain enriches System-2 reasoning with <strong>affordance perception and detailed trajectory IR</strong>, yielding strong transparency and physical feasibility. Although still modular, it covers long-horizon manipulation more effectively by grounding the planner in scene understanding.</p>

<p><img src="/assets/img/dual-system-vla/RoboBrain.png" alt="RoboBrain" /></p>

<hr />

<h2 id="3️⃣-quasi-dual-system-single-model-internal-factorization">3️⃣ “Quasi Dual-System”: single-model <strong>internal factorization</strong></h2>
<p>Some state-of-the-art foundation models <strong>emulate dual-system behavior inside a unified transformer</strong>, blending reasoning, future prediction, and execution.</p>

<h3 id="vla-r1">VLA-R1</h3>
<p>Trained with <strong>SFT + GRPO</strong>, VLA-R1 learns an internal separation between <em>understanding</em> and <em>execution</em>: SFT shapes the model’s semantic and syntactic action space, while GRPO sculpts motion quality and safety. It behaves as if a System-2 policy head supervises a System-1 motor head — but both share a single neural substrate.</p>

<p><img src=".{.{site.baseurl}.}/assets/img/dual-system-vla/VLA-R1.png" alt="VLA-R1" /></p>

<h3 id="univla">UniVLA</h3>
<p>UniVLA integrates vision-language alignment, world-model post-training, and policy learning <em>all within a single autoregressive model</em>: no explicit modular boundaries exist. Yet, its unified token space implicitly carries both System-2 knowledge and System-1 feasibility — a trend toward fully integrated cognitive-motor architectures.</p>

<p><img src="/assets/img/dual-system-vla/UniVLA.png" alt="UniVLA" /></p>

<h3 id="gemini-robotics-series">Gemini Robotics Series</h3>
<p>Gemini-Robotics models can be viewed as evolving toward <strong>a universal brain</strong> capable of reasoning and acting through latent action tokens. Though the exact IR remains opaque, it is clear the model orchestrates planning and control jointly inside a shared transformer world-model.</p>

<p><img src="/assets/img/dual-system-vla/Gemini.png" alt="Gemini" /></p>

<h3 id="worldvla">WorldVLA</h3>
<p>A general transformer world-model is trained to predict action-conditioned future observations and then refined through policy learning. Cognition and execution are ultimately inseparable within this causal predictive substrate — embodying the long-term convergence of dual-system ideas.</p>

<p><img src="/assets/img/dual-system-vla/WorldVLA.png" alt="WorldVLA" /></p>

<hr />

<h2 id="closing-perspective">Closing Perspective</h2>
<p>Across all these lines, we witness a compelling trajectory:</p>

<blockquote>
  <p>Early systems established <strong>clear dual-system decomposition</strong>,<br />
while recent models increasingly pursue <strong>fully unified architectures</strong><br />
— where planning and control co-evolve within a single world-model.</p>
</blockquote>

<p>Yet, the <strong>intermediate representation</strong> remains the linchpin. Whether explicit (waypoints, affordances, spatial relations) or implicit (skill latent, future-state imagination), the IR determines how <strong>System-2 knowledge</strong> shapes <strong>System-1 execution</strong> — and how the body teaches the brain.</p>

<p>This unified view aims to help researchers navigate the rapidly expanding VLA landscape with clarity on the essential design choices shaping embodied intelligence.</p>

<hr />

<!-- 正文到这里结束。 -->

<!-- 上面这一行强制让 Markdown 在 HTML 中被解析。 -->

<script>
</script>


    </div>

  <footer style="margin-top:3rem;text-align:center;color:#aaa;font-size:.85rem;">
    <p>← <a href="/ruihanwu.github.io/" style="color:#007acc;text-decoration:none;">Back to Home</a></p>
  </footer>
</article>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        

<div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/ruihanwu.github.io/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>


<div class="page__footer-copyright">&copy; 2025 <a href="https://daisy-butter.github.io">Ruihan’s Log</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/ruihanwu.github.io/assets/js/main.min.js"></script>









  </body>
</html>
